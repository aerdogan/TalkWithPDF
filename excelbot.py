import os
import streamlit as st
import google.generativeai as genai
import pandas as pd
from dotenv import load_dotenv

# .env'den API anahtarÄ±nÄ± al
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=api_key)

# Gemini modelini baÅŸlat
model = genai.GenerativeModel("gemini-2.5-flash-lite")

st.set_page_config(page_title="Gemini Excel Chatbot", page_icon="ğŸ“Š")
st.title("ğŸ“Š Gemini Excel Chatbot (ilk 50 satÄ±rÄ± baz alÄ±r)")

# Excel iÃ§eriÄŸini saklamak iÃ§in session state
if "excel_text" not in st.session_state:
    st.session_state.excel_text = ""

if "messages" not in st.session_state:
    st.session_state.messages = []

# Excel dosyasÄ± yÃ¼kleme
uploaded_file = st.file_uploader("Bir Excel dosyasÄ± yÃ¼kle:", type=["xlsx", "csv"])
if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)

        # DataFrameâ€™in ilk satÄ±rlarÄ±nÄ± gÃ¶ster
        st.write("ğŸ“„ DosyanÄ±n ilk 50 satÄ±rÄ±:")
        st.dataframe(df.head(50))

        # Tabloyu string olarak sakla
        st.session_state.excel_text = df.to_csv(index=False)
        st.success("Excel baÅŸarÄ±yla yÃ¼klendi âœ…")
    except Exception as e:
        st.error(f"Excel okunamadÄ±: {e}")

# Daha Ã¶nceki mesajlarÄ± gÃ¶ster
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# KullanÄ±cÄ±dan soru al
if prompt := st.chat_input("Tabloyla ilgili bir ÅŸey sorâ€¦"):
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Geminiâ€™den streaming cevap
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        try:
            context_prompt = f"""Sen bir veri analizi yardÄ±mcÄ±sÄ±sÄ±n.
            KullanÄ±cÄ± bir Excel tablosu yÃ¼kledi. Ä°ÅŸte tablo verisi (CSV formatÄ±nda):

            {st.session_state.excel_text[:3000]}  # Ã§ok bÃ¼yÃ¼k dosyalarda ilk kÄ±sÄ±mla sÄ±nÄ±rlÄ±yoruz

            Soru:
            {prompt}

            LÃ¼tfen tablo verisine dayalÄ± olarak cevap ver. 
            Tabloda bulunmayan bilgi hakkÄ±nda "Excel iÃ§eriÄŸinde bu bilgi yok" de.
            """
            
            response = model.generate_content(context_prompt, stream=True)

            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)

        except Exception as e:
            full_response = f"Bir hata oluÅŸtu: {e}"
            message_placeholder.markdown(full_response)

        # Sohbet geÃ§miÅŸine kaydet
        st.session_state.messages.append({"role": "assistant", "content": full_response})
